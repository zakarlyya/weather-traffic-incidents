{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Necessary pySpark imports\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import *\nimport  pyspark.sql.functions as F\nfrom pyspark.sql.functions import concat_ws",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# create a spark session, and read from traffic and weather data\n\nspark = SparkSession.builder.appName(\"traffic\").getOrCreate()\ndf_traffic = spark.read.load('s3://bigdata-seg/data-traffic/traffic.parquet')\ndf_weather = spark.read.load('s3://bigdata-seg/data-weather/weatherbit_weather_2010_2022.parquet')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# use spark withColumn feature to transform RDD and create new columns for Traffic Data\n\ndf_traffic=df_traffic.withColumn('hour_of_day',F.hour(\"measurement_tstamp\"))\ndf_traffic=df_traffic.withColumn('year', F.year(\"measurement_tstamp\"))\ndf_traffic=df_traffic.withColumn('month', F.month(\"measurement_tstamp\"))\ndf_traffic=df_traffic.withColumn(\"day\",F.date_format(F.col(\"measurement_tstamp\"), \"D\"))\ndf_traffic=df_traffic.withColumn(\"window_of_day\",(F.col('hour_of_day').cast('integer')/6).cast('integer') +1)\ndf_traffic=df_traffic.withColumn(\"day_of_week\",F.date_format(F.col(\"measurement_tstamp\"), \"E\"))\ndf_traffic=df_traffic.withColumn(\"window_id\", concat_ws(\".\", \"year\", \"day\", \"window_of_day\"))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# use spark withColumn feature to transform RDD and create new columns for Weather Data\n\ndf_weather=df_weather.withColumn('hour_of_day',F.hour(\"timestamp_local\"))\ndf_weather=df_weather.withColumn('year', F.year(\"timestamp_local\"))\ndf_weather=df_weather.withColumn('month', F.month(\"timestamp_local\"))\ndf_weather=df_weather.withColumn(\"day\",F.date_format(F.col(\"timestamp_local\"), \"D\"))\ndf_weather=df_weather.withColumn(\"window_of_day\",(F.col('hour_of_day').cast('integer')/6).cast('integer') +1)\ndf_weather=df_weather.withColumn(\"day_of_week\",F.date_format(F.col(\"timestamp_local\"), \"E\"))\ndf_weather=df_weather.withColumn(\"window_id\", concat_ws(\".\", \"year\", \"day\", \"window_of_day\"))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# use coordinates for Davison County (geojson.io) to filter Weather Queries by Relevance\n\ndf_weather = df_weather.filter(df_fil.gps_coordinate_latitude >= 36.057)\ndf_weather = df_weather.filter(df_fil.gps_coordinate_latitude <= 36.306)\ndf_weather = df_weather.filter(df_fil.gps_coordinate_longitude >= -86.937)\ndf_weather = df_weather.filter(df_fil.gps_coordinate_longitude <= -86.621)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# write changes to new S3 path\n\ndf_weather.write.parquet(path='s3://bigdata-seg/weather-data-filtered')\ndf_traffic.write.parquet(path='s3://bigdata-seg/traffic-data-filtered')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}